%Kahn's fixed-point semantics:
%A network of continous functions is continous
\chapter{Theoretical Background and Related Work}
In this chapter we provide relevant theoretical background in coordination programming and stream processing. We pick a recent component system example from each field. Then, we descride the combined approaches to coordination programming and stream processing S-Net and \ak\ and explain the concepts behind \ak\ in more detail. We sum up the chapter with the comparisson of the four components systems, including their approaches to synchronisation.


%Approaches to synchronisation.
%Synchronisation facilities in coordination languages.
    \section{Coordination Programming}
The coordination paradigm offers a promising way to address some issues related to the development of efficient parallel systems. Programming a parallel system can be seen as the combination of two activities: the actual computing part comprising a number of processes that manipulate data and a coordination part that is responsible for the communication between the processes.

Basically, coordination is managing dependencies between components. Since the computation is completely separated from the coordination activity, the processes that comprise the former are seen as black boxes. Hence, the actual programming languages used to write the computational code do not play important role in setting up the coordination scheme. Thus, the concept of coordination is closely related to heterogenity.

Existing coordination models\footnote{A coordination model constitutes the entities being coordinated, the means used to ccordinate the entities and the semantic framework the model adheres to} are described in details in the survey \cite{papadopoulos} by G. Papadopoulos and F. Arbab. They argue that these models fall into two major categories of coordination programming, namely either data-driven or control-driven.

The main characteristic of the data-driven coordination models is that coordinated processes are responsible for both examining and manipulating data as well as for coordinating either themselves and/or other processes by invoking the coordination mechanism each language provides. This means that the coordination and computation code are mixed within the process definition. A data-driven coordination language typically offers several coordination primitives which are mixed with the purely computational part of code.

Many data-driven coordination models have evolved around the notion of a shared dataspace. The shared dataspace plays the dual role, being a global data repository and an interprocess communication system. The processes communicate among themselves writing to the shared dataspace and retrieving data from it. Hystorically the first member of this family is Linda \cite{linda}.

Strictly speaking, not all data-driven coordination models follow the above pattern of coordination. Some of them use a message-passing based mechanism (MPI, \cite{mpi}).

Opposite to the data-driven coordination model, the control-driven coordination model achieves almost complete separation of computation and coordination concerns. This is usually achieved by defining a special language that offers facilities for controlling synchronisation, communication, creation and termination of computing components. One of contemporary members of this family is Reo \cite{Reo_Arbab04}.

In Reo the computational components communicate via complex coordinators, or \emph{connectors}. An undirected channel is an atomic connector in Reo. Channels are typed, however, no fixed set of types is assumed. The channel type defines the synchronisational behaviour of the channel with respect to data.

Channels are connected with \emph{nodes}. Nodes have fixed merger-replicator behaviour: the data of one of the incoming channels is propagated to all outgoing channels, without storing or altering the data. If multiple incoming channel can provide data, the node make a nondeterministic choice among them.

Complex connector in Reo is represented as undirected graph contisting of channels and nodes. C. Baier et al. propose \emph{constraint automata} as an operational model for component connectors in Reo \cite{baier_ca}.


    \section{Stream Processing}
The term stream processing refers to the study of a number of disparate systems, such as dataflow systems, reactive systems, signal processing systems, etc. However, conceptually the analysis of each of these systems is usually based on the study of a patricular type of stream processing system. A stream processing system is a system comprised of a collection of processes that compute in parallel and communicate data via channels. The processes are ususally divided into three classes: sources that pass data into the system, filters that perform some atomic computation, and sinks that pass data from the system. Stream processing systems are usually visualised as directed graphs.

An overview of the hystorical development and the discussion of the different techniques for streams programming is presented in the survey by R. Stephens \cite{stephens97}. Stephens identifies that the first type of stream processing systems are dataflow systems. In the first dataflow programming language Lucid \cite{lucid}, each variable is represented as an infinite stream of values. Computation is carried out by defining transformation functions that process these streams. Lucid is possibly the first language to introduce the idea of a filter.

A significant result for concurrency engineering is Kahn's work \cite{kahn74} that outlines the semantics of a simple parallel programming language. Kahn suggests a distributed model of computation where a group of deterministic sequential processes communicate via unbounded FIFO channels under the following assumptions:
\begin{itemize}
\item Channels are the only way for processes to communicate
\item Channels transmit messages within a finite time
\item At any given time a process is either performing computation or waiting for messages on one of its input channels.
\end{itemize}
Kahn proved that the output of the resulting process network is deterministic, i.e. it does not depend on the mutual order of computations at different nodes. The model is now referred to as Kahn Process Network (KPN).

A Kahn process may have multiple input and multiple output channels. Reading from a channel in KPN is blocking, i.e. a process that reads from an empty channel stalls and can only continue when the channel contains sufficient data.  On contrary, writing to a channel is non-blocking and it always succeeds since channels capacity in KPN is unlimited. Processes cannot test an input channel for data availability without consuming the data. KPNs allow arbitrary wiring, i.e. the network may have feedback communication.

In KPNs the number of data elements a process might read from a channel or write to a channel is not restricted. In synchronous dataflow (SDF, \cite{sdf}) the consumption and production rates of a process that is ready to perform the computation are fixed. Hence, an SDF process computes in a synchronised manner with respect to the processes it is connected to.
%Synchronous dataflow is a restriction of KPNs.
%From operational point of view the dataflow model of computation is divided into two basic froms: data-driven (filters compute depending upon the availability of data at their inputs), and demand-driven (filters request data on the input lines when they wish to compute).

A recent SDF implementation in programming languages is StreamIt \cite{streamit}. The basic unit of computation in StreamIt is a user-defined single-input single-output (SISO) block that translates input data sequences to output sequences called a filter. A filter can communicate with neighbouring blocks via FIFO channels. StreamIt imposes structuring on applications with the following structural primitives:
\begin{itemize}
\item \emph{Pipeline} specifies sequential composition of filters,
\item \emph{SplitJoin} specifies parallel composition of filters,
\item and \emph{FeedbackLoop} provides a way to create loop constructs in a streaming network.
\end{itemize}
A StreamIt program is a hierarchical composition of these constructs.

With the restriction to a single input and a single output, a filter is relieved from questions to what extent to synchronise data on multiple input channels and to which of multiple output to send the output.


\section{Combined Approaches to Component Systems}

    \subsection{S-Net}
S-Net \cite{snet_intro} is a declarative coordination language based on stream processing. S-Net defines the coordination of stateless asynchronous components (boxes) that interact with each other in a streaming network. Boxes are written in conventional languages that are subject to contract with S-Net. Boxes execute fully asynchronously, i.e. a box may consume data as soon as it is available in the input stream. Moreover, boxes are SISO, therefore S-Net achieves a near-complete separation of communication and computation concerns.

%five combinators, feedback
Streaming networks are expressed in a hierarchical composition of a fixed set of four combinators, namely serial composition, parallel composition, serial replication and parallel replication. All the combinators except for the serial composition are non-deterministic in a sense that the input data may be reordered in the output stream. For non-deterministic combinators there exist deterministic variants.

S-Net provides a special kind of box, called a synchrocell, that implements barrier synchronisation on streams. Data on streams are organised as records of label-value pairs. A synchrocell maintains an internal state in order to keep a record coming from each of its input streams. Once a synchrocell has collected records from all of its input streams, it merges the records into a single one and emits then the result to the output stream.


%Optionally: synchronisers can be used for monitoring of network
    \subsection{\ak\ }
%In this section we present the concepts of a new coordination language \ak\.
\ak\ is an attempt to combine coordination programming with stream processing in order to provide a component system with concurrency self-regulation. \ak\ defines the coordination behaviour of fully asynchronous components (boxes) and their orderly interconnection via stream-carrying bounded FIFO channels. In \ak\, data on streams are organised as collections of labeled alternative records. Each record constitutes a message.

Like S-Net, \ak\ provides a facility for stream synchronisation in a form of a special component called a synchroniser. The behaviour of a synchroniser is not fixed; instead, it is defined in a dedicated language that is a part of \ak\ paradigm. An \ak\ box is not SISO. Usually it has a single input channel, however, the number of output channels is not restricted. In order to allow the dynamic reconfiguration of \ak\ networks, a box is required to have no state, which it can maintain between two consecutive activations. Since a box is stateless, it does not know to what extent to synchronise the messages it sends to the output channels; this part of work is done by synchronisers. In addition, a synchroniser is not just a tool that is able to combine and store received messages; it can compute some trivial message extensitons. With synchronisers, \ak\ achieves a separation of computation and coordination concerns.

%wiring
\ak\ imposes structuring on streaming networks with a total of four combinators, namely the serial connection, the parallel connection, the wrap-around connection and the serial replication. Network combinators may take either boxes or networks as their operands, hence the network construction is an inductive proccess. 

In the following sections the concepts of \ak\ are explained in more detail.


    \subsubsection{Channels}
Channels in \ak\ are named FIFO queues with a limited capacity. A channel carries a segmented stream that consists of message sequences and these sequences may in turn consist of sequences in their own right. In order to mark the beginning and the end of a sequence, \ak\ supports a special kind of message called a segmentation mark.

Segmentation marks can be thought of as brackets. \ak\ requires that a stream of message sequences that flows through a channel has the static bracketing depth. Therefore, each message in a given channel is under all circumstances found between the same number of brackets. In this case, further into the message sequence brackets can occur only in the following combination:
\[
\underbrace{)\ldots)}_k \underbrace{(\ldots(}_k\,,
\]
where $k \le d$, and $d$ is the number of opening brackets in the beginning of the stream. This combination is denoted as a segmentation mark $\sigma_k$. The bracketing depth $d \ge 0$ characterises the stream-carrying channel and is know statically\footnote{Indeed, the bracketing depth of a channel that would carry the stream of message lists
\[
(((\;a\underbrace{)(}_{\sigma_1}b\underbrace{))((}_{\sigma_2}c\underbrace{)(}_{\sigma_1}d\;)))
\]
is 3}.


    \subsubsection{Boxes}
Boxes are the atomic building blocks of \ak\ networks that actually perform the computation. An \ak\ box is deterministic in a sense that for every partial input stream it produces a deterministic output stream\footnote{For a function $f(x): \mathcal{I} \to \mathcal{O}$, where $\mathcal{I}$ is the totality of $f(x)$ input streams and $\mathcal{O}$ is the totality of $f(x)$ output streams, $\forall p \in \mathcal{I} \land \forall t:p \cup t \in \mathcal{I} \: : \; f(p \:||\: t) = f(p) \:||\: f(t)$}.

Conceptually, boxes can be specified in any conventional programming language, however, they are subject to a contract that defines acceptable behaviour for boxes. Any guarantees that \ak\ makes\footnote{E.g. regarding ordering of messages in the input channels} are subject to the fulfilment of the contract on behalf of all the boxes. The interface between a box and the \ak\ runtime system is defined by the \ak\ Box-API for each supported box language.

\ak\ declares seven box categories with respect to their algebraic properties and effect of channel segmentation\footnote{The box code does not see the segmentation marks; instead it is declared as having a certain type of bracketing behaviour so that \ak\ can take care of the brackets}:
\begin{description}
\item[Transductor]
A transductor has one input channel and one or more output channels and responds with no more than one output message on each of its output channels. Segmentation marks are passed on to all the output channels of the box, bypassing the box code.

\item[Inductor]
An inductor has one input channel and one or more output channels and responds to a single message from the input channel with a sequence of messages on each of its output channels. Before the input stream is passed to the inductor, each $\sigma_k$ in it with $k > 0$ is replaced by $\sigma_{k+1}$, and a $\sigma_1$ is inserted between every two consecutive data messages. Segmentation marks are bypassed from the input to all the output channels by the coordinator when encountered at the input of the inductor.

\item[Reductor] A reductor implements the reduction operation for a list of input messages. All reductors have a single output channel. \ak\ classifes reductors by the number of input channels and properties of the reduction operation they implement. There exist five classes of reductor:

    \begin{description}
    \item[Dyadic ordered] A dyadic ordered reductor has two input channels. The first input channel is reserved for the initial value. The reduction operator is applied to the messages in the order they arrive on the second input channel

    \item[Dyadic unordered] Same as dyadic ordered except for the reduction operator can be applied to the messages on the second channel in any order without affecting the result

    \item[Monadic ordered and monadic unordered] Same as dyadic reductors except monadic reductors have one input channel. A monadic reductor is only run when two messages are received

    \item[Monadic segmented] A monadic reductor recursively processes an input list of messages that can be segmented into arbitrary sublists until the list is reduced into a single message
    \end{description}
\end{description}


    \subsubsection{Synchronisers}
Synchronisers are non-deterministic finite state machines for joining messages and sending them on to the output channels. \ak\ provides synchronisers a finite memory in order to store received messages.

A synchroniser can have any number of input and output channels. Unlike boxes, synchronisers maintain an internal state and generally accept messages from each input channel in some states, while in any of the other states the channel is blocked until a state transition brings the synchroniser to a state in which messages from the channel are accepted.

A synchroniser can compute trivial extensions for messages. For example, it can add a labeled integer value to a message. It also detects segmantation marks in a an input stream and can change the segmentation of the stream by creating segmentation marks and sending them on to the output channels.

The state transitions of a synchroniser can depend on the content of the current message but never on that of a stored one. In order for the synchroniser to read the field values of the current message, it is matched with a pattern specified within the triggering condition of the transition. In addition, the triggering condition may check the matched values if they are known to be integers. If the message was matched and the integer values are satisfactory, then the transition fires.

The act of sending a message to the output channel is associated with a transition. Once the transition is known to fire, the synchroniser computes the message extensitons, joins the parts of the message together and sends it on to the output channel.

\ak\ provides a dedicated language to describe synchronisers. A synchroniser program is a list of the synchronisers' states. Each state lists the state transitions.
%If a continous synchronisation is desired, the synchroniser must be programmed so that it looped around some state.


    \subsubsection{Network Composition}
The construction of streaming networks in \ak\ is hierarchical: components are wired into a subnetwork, which in turn can act as a component in a larger network, etc. In order to wire the components, \ak\ provides a set of wiring patterns that is sufficient to achieve arbitrary wiring. A pattern is applied to its operand networks, either boxes or synchronisers. The pattern identifies input/output channels of the operand(s) with one another and with the input/output channels of the result.

Wiring patterns form a set of four in total. Three out of four are static, applicable to one or two operands:
\begin{description}
\item[Serial connection] applies to two operands. All outputs of the first operand are wired to identically named inputs of the second operand if they exist. The rest of the channels contribute to the input/output sets of the resulting network.

\item[Parallel connection] applies to two operands. Two operand networks are placed side by side without connection and their input and output channels form the input and output channel sets of the resulting network.

\item[Wrap-around connection] applies to a single operand. Each output channel of the operand that matches an input channel by name is wired to it with a special wrap-around channel, thus completing a cyclic connection. In order to avoid deadlocks, \ak\ does not limit the capacity of wrap-around channels; their capacity is only limited by the amount of memory available for the queues in the system.
\end{description}
These three patterns are sufficient to achieve arbitrary wiring of the components. %TODO: mergers!

The fourth pattern -- \textbf{serial replication} -- replicates the single operand network infinitely and wires up the consequent replicas with the serial connection. The actual replication is demand-driven, hence the chain of replicas is extended dynamically at runtime. The output from the infinite chain is organised via a special channel the programmer has to declare. Once a replica sends a message to the channel, the channel is dynamically wired to the rest of the \ak\ network.
%All wiring patterns in \ak\ except for the serial connection are the source of non-determinism. non-determinism comes from non-deterministic mergers.


    \subsubsection{The Type System of \ak\ }
The type system of \ak\ is based on the Message Definition Language (MDL, \cite{astrakahn}) which is a language of abstract terms that are built recursively from the ground up. Structurally the terms are symbolic trees with the following kinds of leaf:
\begin{description}
\item[Symbol, Number, String] terms represent a certain finite quality
\item[Variable] term ranges over terms
\item[Flag] is a boolean variable that only occurs in a certain context.
\end{description}
Other terms are built recursively using the following types of constructor:
\begin{description}
\item[Tuple] is a collection of terms in linear order
\item[List] is an extensible collection of terms in linear order
\item[Record] is an extensible collection of label-term pairs
\item[Choice] is an extensible collection of labeled alternative terms
\item[Switch] is a collection of guarded terms that represents exactly one of them depending on the value of the boolean guards
\end{description}

Data on streams are organised as collections of labeled alternative records (choices). If a choice is known to carry a single record, this record is labeled \emph{uniq}.

An \ak\ component, either a box or a synchroniser, is both a consumer and a producer for some other components in the network. Hence to guarantee the static correctness of a channel, the subtyping relation between the consumer's input and the producer's output types must hold. In order to check the static correctness over the network, a component can be abstracted with respect to its data-transformation behaviour as an implicative statement $p \Rightarrow P$, called a passport, where $p$ is the type of the input message and $P$ is the type of the output message. During the check, the \ak\ compiler extracts the topology of the network, forms the subtyping relations between the passports and performs constraint solving in order to instantiate all term variables. If the constraint system is satisfiable, then the whole program is consistent and type correct.
%The role of the CAL in AstraKahn is similar to the role of the type system in a conventional programming language. The CAL is, in a way, a universal type system in the sense that it does not fix the structure and meaning of the type assertions that boxes may choose to import and export. It instead provides a constraint programming framework in which a wide variety of assertions can be formulated. It relies on general-purpose constraint solving as a means of type checking, type inference and most general subtyping.


%Change the title
    \subsubsection{Structure of \ak\ }
\ak\ is motivated by a KPN, which is a theoretical model and its properties are only available under an interpretation with unlimited resources. The intention of \ak\ is to refine and structure KPNs in order to provide a component system with an automatic resource and concurrency management.

%What properties of KPNs do \ak\ inherit? What are the differences?
\ak\ provides the following refinements for KPNs:
\begin{itemize}
\item \emph{Complete separation of coordination and computation concerns} opens opportunities for parallelisation. Computational components are stateless and the coordination logic is expressed in the network wiring and synchronisers

\item \emph{Automatic resource and concurrency management} provides a communicational demand based parallelisation mechanism and takes care of the queue sizes in the network

\item \emph{Separation into independent layers communicating by means of interfaces} addresses the standard engineering agenda of abstraction, encapsulation and hierarchical development.
\end{itemize}

As the result of the refinement, \ak\ is seen as a construction of three independent layers:
\begin{itemize}
\item The Topology and Progress Layer (TPL) that defines:
    \begin{itemize}
\item[-] Classes of boxes, their algebraic properties and their effects on channel segmentation
\item[-] The language for synchronisers
\item[-] The wiring patterns and the subnetwork encapsulation facility
\item[-] The automatic resource and concurrency management strategy
    \end{itemize}

\item The Constraint Aggregation Layer (CAL) that insures type safety all over network with data constraints provided by each component

\item The Data Instrumentation Layer (DIL) that manages data distribution and concurrent memory access.
\end{itemize}


    \section{Summary}
In this chapter we have reviewed recent component systems based on coordination programming (\emph{Reo}) and stream processing (\emph{StreamIt, S-Net}), and described the approach to component coordination that is being developed within the \ak\ project.

The stream processing based approaches StreamIt, S-Net and \ak\ impose structuring on networks with fixed sets of combinators, while the coordination language Reo allows an arbitrary component connection. In Reo, the computational components are connected into a network with complex connectors that are constructed of channels typed with respect to their synchronisation properties. Just like the Reo's approach to data synchronisation, S-Net achieves a near-complete separation of computation and communication concerns. However, in S-Net, the computational component's interface is restricted to a single input and a single output channel. Addinionally, S-Net provides a stream synchronisation facility called a synchrocell that implements barrier synchronisation on streams. \ak\ does not put a restriction for computational components to have a single input and a single output channels. Instead, \ak\ provides a tool for a more complex stream synchronisation called a synchroniser. Unlike a Reo connector or an S-Net synchrocell, an \ak\ synchroniser is able to process messages, e.g. read and change their content to some extent. With synchronisers, \ak\ achieves a separation of computation and communication concerns. Like in S-Net, the computational components in StreamIt have a single input and a single output channel. Moreover, StreamIt is based on the synchronous dataflow model, where neighbouring components communicate synchronously. With these properties the components in StreamIt are relieved from question to what extent to synchronise data.

In order to support the dynamic reconfiguration of streaming networks, S-Net and \ak\ require the computational components to have no state. A heuristic scheduler that utilises positive and negative demands of the stream communications was developed for S-Net in \cite{nga}. The ability to dynamically reconfigure a streaming network opens opportunities for parallelisation. The long-term goal of the \ak\ project is to provide a self-regulating concurrency mechanism based on the communicational demand. StreamIt does not require the components to be stateless; it relies on the static scheduling of the synchronous data flow programs. Reo is clueless about the components it coordinates; it focuses on the components connection, rather then on the components themselves.
%
%Queue size management - StreamIt is a SDF system, therefore management of channels size is easy, because the consumption and the production rates of each component are fixed and known in advance. Reo and S-Net do not care. AK attempts to provide the automatic resource management.
%
%In this thesis we focus on the \ak\ approach to stream synchronisation.
