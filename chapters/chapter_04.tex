\chapter{Towards statistical properties of synchronisers}
Brief explanation of the role of synchronisers in learning for proliferation (that initial throughput value estimation is needed as well as initial channel sizes)

How did we come to the idea of using a statistical model?
What is a statistical model in general? (See wiki page) How are they used?
The practical side of statistical model: The model of the relatioships between various object parameters
 
In absence of environment for experiments and example applications artificial load is used.

%Практический смысл статистической модели:
%1) Характеристики $T'_{i}, \; j'_{i}$ являются начальными значениями для алгоритма пролиферации
%2) Начальные размеры каналов

\section{Statistical model}
Let $S = (\Phi, \; \Pi)$, where $\Phi = (A \subseteq C \times P, \; S, \; T)$, $\Pi \: : \: S \times \Omega \to V$ be a synchroniser with $|C| = m$ input channels, $|\Omega| = n$ output channels and the transtion matrix $T$. All channels $c_{i}, \: i = 1,m$ and $\omega_{i}, \: i=1,n$ are finite FIFO-queues that have lengths $L^{(in)}_{i}, \: i = 1,m$ and $L^{(out)}_{i}, \: i=1,n$ as shown in Fig. \ref{fig:stat_mod}.

% Inkscape figure
  \begin{figure}[h] %here!
  \scalebox{0.8}{
    \includesvg{figs/stat_mod}
  }
  \caption{A statistical model of a synchroniser}
  \label{fig:stat_mod}
  \end{figure}

%Explaining basic structure of channel and input channel producer properties
Every input channel $c_{i}, \; i = 1,m$ is connected to a producer $P_{i}$ that sends to this channel on average of $T_{i}$ messages per unit time with an independent jitter (i.e. standard deviation) $j_{i}$. $T_{i}$ may also be interpreted as the throughtput of the $i$-th producer. The output parameters of the synchroniser $T_{i}$ and $j_{i}, \; i=1,n$ assume that the channel $c_{i}$ has infinite length.

%Explaining synchroniser consuming characteristics
When messages are placed on a synchroniser's input queue they may or may not be consumed immediately. In some states the synchroniser may block the input channel. Let $T'_{i}, \: i=1,m$ be the average number of messages accepted by the synchroniser per unit time and $j'_{i}$ the standard deviation of $T'_{i}$.

%Synchroniser producing characteristics
A synchroniser is the producer for its output queues $\omega_{i}, \: i=1,n$. Let $T'_{i}, \: i=1,n$ be the average number of messages sent by the synchroniser to the output channel $\omega_{i}$ per unit time and $j'_{i}$, again, the standard deviation of $T'_{i}$.

%Ouptut channels consumers
The synchroniser's output channels are connected to processes $C_{i}, \: i=1,n$ that consume messages from these channels. Let $T_{i}, \: i=1,n$ be the average number of messages consumed by the process $C_{i}$ per unit time and $j'_{i}$ the standard deviation of $T_{i}$.

%problem statement
\begin{problem}Find relations between $(T_{i}, \: j_{i})$, $(T'_{i}, \: j'_{i}), \: i=1,m+n$, $L^{in}_{i}, \: i=1,m$ and $L^{out}_{i}, \: i=1,m$.
\end{problem}

%From statistics point of view
The model can be constructed in a different way. We focus on the interarrival time of messages instead of the throughput of the components. The interarrival time $t_{i}, \: i=1,m+n$ of messages in the channel $c_{i} \cup \omega_{i}$ is a random variable distributed according to a continuous two-parameter probability density function $p_{i} \: (t < t_{i}) = p_{i} \: (\mu_{i}, \sigma^2_{i}, t_{i})$, where $\mu_{i} = E[t_{i}]$ is the expectancy and $\sigma^2_{i} = Var[t_{i}]$ is the variance of $t_{i}$.

%%
%% TODO Draw a picture:
%%             t_i
%%        *-----------*
%%  ------*-----------*--------> t
%%        i          i+1
%%

If the interarrival time $t$ has the PDF $p_{t}(t)$ then the throughput $T = \frac{1}{t}$ has the PDF $p_{\frac{1}{t}}(t)$ that is inverse to $p_{t}(t)$. An inverse distribution is obtained by applying the transformation theorem (TODO: reference a good book) to $p(t)$. The transformation theorem states that for a continuous random variable $X$ with the PDF $p_{X} (x)$ and a function $g$ that is monotonous on its domain of definition the random variable $Y = g(X)$ has the PDF $p_{Y} (x) = |\frac{d}{dx}g^{-1}(x)|\cdot p_{X} (g^{-1}(x))$, where $g^{-1}(x)$ is the inverse function for $g(x)$ and $\frac{d}{dx}g^{-1}(x)$ is its derivative. Applying the theorem for the interarrival time $t \sim p_{t}(t)$ and the throughtput $T = g(t) = \frac{1}{t} \sim p_{\frac{1}{t}}(t)$ we get
\begin{IEEEeqnarray}{rCl}
g^{-1}(t) &=& (\frac{1}{t})^{-1} = \frac{1}{t}\nonumber\\
p_{\frac{1}{t}}(t) &=& |\frac{d}{dt}(\frac{1}{t})| \cdot p_{t}(\frac{1}{t}) = \frac{1}{t^2} \cdot p_{t}(\frac{1}{t})\nonumber
\end{IEEEeqnarray}
Knowing $p_{\frac{1}{t}}(t)$ the expectancy and the variance of the throughtput $T$ are obtained from the standard formulae
\begin{IEEEeqnarray}{rCl}
E[T] &=& \int_{0}^{\infty} t \cdot p_{\frac{1}{t}} (t) dt = \int_{0}^{\infty}\frac{1}{t} \cdot p_{t}(\frac{1}{t}) dt\nonumber\\
Var[T] &=& \int_{0}^{\infty} t^2 \cdot p_{\frac{1}{t}} (t) dt = \int_{0}^{\infty}p_{t}(\frac{1}{t}) dt\nonumber
\end{IEEEeqnarray}

\section{I don't know how to name it}
When all the time $T_{i} > T'_{i}$, $i=1,m$ then it doesn't matter what is the length of the input queue $L^{(in)_{i}}$ it will always be full. The same is with the output queues of the synchroniser: when $T'_{i} > T_{i}$, $i=1,n$ the output queue $L^{(out)}_{i}$, $i=1,n$ will always be full. Therefore, we are only interested in cases where $T_{i} = T'_{i}$, $i=1,m+n$. We are seeking for the queue lengths $L_{i} = L_{i} (T_{i}=T'_{i}, j_{i}, j'_{i})$, so that anytime the number of messages in the queue would be $l_{i} < L_{i}$. In other words, we are seeking for the queue length $L_{i}$ that minimizes the probability of messages loss for given jitters $j_{i}$ and $j'_{i}$ and rate $T_{i} = T'_{i}$.

We have 3 parts to analyse in the system:
\begin{enumerate}
\item The producer $P_{i}$, $i=1,m$ send out messages into the output channel with the rate $T_{i}$ and the jitter $j_{i}$ in assumption the output channels have infinite length. The synchroniser connected to this channels then consumes the messages with the rate $T'_{i} = T'_{i} (T_{i}, TD)$. When the length of the channel $L_{i}$ is finite and one the jitters $j_{i}$ and $j'_{i}$ is too big the channels may sometimes get full. The producer is suspended when it output channels are full, thus the full channel affects $T_{i}$ and $j_{i}$ of the producer.

\item The influence of $TD$ on the syncroniser's output rates. Messages arrive to the synchroniser's input channels with the rates $T_{i}$ and jitters $j_{i}$, $i=1,m$. Find the output rates $T'_{i} = T'_{i} (T_{i}, TD)$ and jitters $j'_{i} = j'_{i} (j_{i}, TD)$, $i=1,n$ in assumption that the input and the output channels are infinite.

Assume the synchroniser produces one message in the $i$-th output channel immediately when it has $(N_1, N_2, \dots N_m)$ messages in its input channels $(c_1, c_2, \dots c_m)$. The the arrival of the message to the $i$-th output channels happens the most often when $E[N_1 \cdot c_1] = E[N_2 \cdot c_2] = \dots = E[N_m \cdot c_m]$ and $Var[N_1 \cdot c_1, N_2 \cdot c_2, \dots N_m \cdot c_m]$ is minimal. $N_i \cdot c_i$, $i=1,m$ here denotes the event of arrival of $N_i$-th message in the channel.

For a Poisson process $Pois(\lambda)$ the arrival of the $n$-th message is distributed according to the Erlang distribution $Erlang(n, \lambda)$ with the expectancy $\frac{n}{\lambda}$ and the variance $\frac{n}{\lambda^2}$.

Draw graphs for the pure zip2 throughput(variance) with infinite queue lengts for Poisson processes and for inverse gamma processes. Probably draw a graph for the less trivial synchroniser, for ex. (a,2b)->c.

\end{enumerate}

We have to somehow find the balance equations for the synchroniser to consider it all.


Proliferation: combining and splitting Poisson processes


\textbf{Some obvious properties of the model}
Let $l_{i}, \; i = 1,n$ be the actual number of messages stored in any moment of time in channels $L_{i}$. Then the following is true:
  \begin{itemize}
  \item If anytime $l_{i} < L_{i}$, then $T'_{i} = T_{i}$, $i = 1,m$;
  \item If sometime $l_{i} = L_{i}$, then $T'_{i} < T_{i}$, $i = 1,m$;
  \item If $l_{i} > 0$, then $T'_{i} = T_{i}$, $i = m+1,n$;
  \item If $l_{i} = 0$, then $T'_{i} < T_{i}$, $i = m+1,n$.
  \end{itemize}


\section{The plan of study}
%TODO: These all need better explanation w.r.t (Some obvious properties of the model)
%Influence of finite input channel lengths on producers


$T_{i}$ and $j_{i}, \; i=1,m$ are the characteristics of producers in assumption that the channels $c_{i}, \; i=1,m$ they are connected to, are infinite. A finite channel length affects these values. If a channel is full, messages can't be placed in it anymore, so $T_{i}$ decreases. (TODO: what happens to $j_{i}$, does it decrease as well?)

%Synchroniser input characteristics
The affected values $T_{i}, \; j_{i}, \; i=1,m$ change $T'_{i}, \; j'_{i}$. Also $T'_{i}$ and $j'_{i}$ are affected by the transition diagram of a synchroniser causing input channel blockings.

%Influence of finite output channel lengths on synchroniser
If output channels of a synchroniser have finite lengths, it affects the output characteristics of a synchroniser $T'_{i}$ and $j'_{i}, \; i=m+1,n$ as finite input channels lengths affect producers.

%Influence on synchroniser consumers
The characteristics of synchroniser consumers are not affected directily by finite channels lengths. They are directly affected by $T'_{i}$ and $j'_{i}, \; i=m+1,n$.


%The plan of study
%What kind of synchronisers is studied
In this project we study only synchronisers whose transition diagrams have deterministic transitions, i.e a transition diagram doesn't depend on message content. If more that one transition possible at the same time, than all choices are made with the same frequency.

%Describe the idea for a study. We have 3 problems with a synchroniser: input channels are finite, transition diagram is random (fixed by the language), output channels are finite. Decribe the order in which these problems are studied (the strategy).

We break down the problem into parts:
  \begin{enumerate}
  \item Study the part of a system that doesn't depend on the output channels
    \begin{itemize}
    \item Find $T'_{i}$ and $j'_{i}, \; i=1,m$ depending on $T_{i}, \; j_{i}, \; i=1,m$ and finite channel lengths $L_{i}, \; i=1,m$;
    \item Investigate how $T_{i}, \; j_{i}, \; i=1,m$ are affected by $L_{i}, \; i=1,m$;
  \end{itemize}

  \item Study the part of a system that depends on the output channels
    \begin{itemize}
    \item Find "ideal" $T'_{i}$ and $j'_{i}, \; i=m+1,n$ with assumption that output channels have infinite lengths;
    \item Study an impact of finite output channels on $T'_{i}$ and $j'_{i}, \; i=m+1,n$;
    \item Investigate how $T_{i}$ and $j_{i}, \; i=m+1,n$ of consumers are affected.
    \end{itemize}
  \end{enumerate}


Stability condition $\frac{\lambda_{arr}}{\lambda_{dep}} < 1$.
\section{Relevant work}


Queueing theory, queueing networks with blocking
-Poisson
-Non-poisson
Production systems perfomance


\section{Modeling a system}

  \subsection{Modeling channels}
Channels act as FIFO-queues. Message arrivals in a channel are independent events with interarrival time $\Delta t$ distributed according to the gamma distribution: $\Delta t \sim Gamma (k, \theta, t)$. Gamma distribution is chosen because of two reasons:
    \begin{itemize}
    \item it is a well-studied distribution that generates positive values, i.e. its domain of definition is $t \in [0;\infty]$, and interarrival times must be positive,
    \item it is closed to the convolution operation if the parameter $\theta$ is fixed: $Gamma_(k_{1}, \theta) * Gamma (k_{2}, \theta) = Gamma (k_{1} + k_{2}, \theta)$; this property helps to significantly simplify heavy computations involving convolutions.
    \end{itemize}

According to the central limit theorem, any distribution could be chosen -- it should not change results significantly. (Explain why?)

TODO Put a graph somewhere with the number of messages in a channel over time (the channel is finite and connected to a synchroniser) Probably appendix with the Brownian motion

  \subsection{Modeling artificial load}
Describe the modeling of a synchroniser with a general case transition diagram (data structures, algorithms, tools, etc)
    \begin{itemize}
    \item For the unlimited queue
    \item For the limited queue
    \end{itemize}

  \subsection{Limitations of the model}
Describe the limitations of this model (only considers choosing a transition by choice frequency if more than one channel are ready)


\section{Application of Markov chains to synchronisers}
In this section we explain how to find $T'_{i}$ and $j'_{i}, \; i=1,n$ using discrete-time Markov chains.
  \subsection{Introduction to discrete-time Markov chains}
A short introduction to discrete-time Markov networks.

The states and the transition probability matrix $P$. The transition probabilities do not depend on how the state was reached. The matrix $P$ has the following properties: the sum of all elements in each raw is 1, and $lim_{n - \infty} P = P_{steady}$. The elements in each column of the matrix $P_{steady}$ have the same value and the sum of elements in (each) raw is 1. These probabilities are called steady state probabilities.

  \subsection{Structure of a chain}
\textbf{States} States of a chain describe all the possible states of input channels. By a state of a channel at time $t$ we assume the number of messages stored in it at time $t$. If a synchroniser has $A^1, \; A^2, \; \cdots A^m$ input channels, then the states of a corresponding chain are $A^1_{l_1} A^2_{l_2} \cdots A^m_{l_m}$, where $l_i, \; i=1,m$ is the number of messages in the channel $A^i$ at any time $t$.

    Provide a sketch of the algorithm to find the states. The algorithm is recursive. We have the reduced set of events that corresponds to time $t$ we chose. Then we put each event of the set to the synchroniser and record the state of queues. We run this procedure for each new state we get until we get a new state. This algoritm stops because the queues, the set of events and the set of states of he synchroniser are all finite.


\textbf{Transitions}
A transition is any tuple of messages we may get in the channels during time $t$. Defining a transition like this we state that any state is reachable from any state with just one step (need a proof?).
However, making a transition $(a^1,a^1)$ from the state $A^1_{l_1=1} A^2_{l_2}$ in the system where $|A^1|=2$ produces a lost message on the channel $A^1$. To consider lost messages we modify the state adding the number of lost messages to it: $A^1_{l_1} L^1_{k_1} A^2_{l_2} L^2_{k_2}$.

For example, take an abstract system having 2 input channels of length $l>2$. Assume the system is in such state when the chain is in state $A^1_0 A^2_0$ and the channel $A^2$ is blocked. During some time $t$ we may get any number of messages in the input channels. We consider transitions where we get 0 or 1 messages in each input channel $A^i, \; i={1;2}$. The interarrival time in both channels is Gamma-distributed with parameters $k=2$ and $\theta=0.5$: $t \sim Gamma \: (t,\theta)$. Then the probability to have one message in a channel is $p = p\:(t) = Gamma \:(k,\theta,t)$. The probability to have one message in a channel and not to have a message in another channel $P_{1,0} \: (t) P_{0,1} \: (t) = p(1-p)$. The probability to have messages in both channels $P_{1,1} = p^2$.

(A graph showing $p_{1,0}(t)$ and $p_{1,1}(t)$)

Whe can chose $t$ so that many transitions are cut off because their probability is very small.



A transition from the state $A^1_{l^1_1} A^2_{l^1_2} \cdots A^m_{l^1_m}$ to the state $A^1_{l^2_1} A^2_{l^2_2} \cdots A^m_{l^2_m}$ when we get $(l^2_1-l^1_1)$ messages in $A^1$, $(l^2_2-l^1_2)$ messages in $A^2$, \dots and $(l^2_m-l^1_m)$ messages in $A^m$. Because state machine recieves one symbol at time, there will be $\sum_{i=1}^{m}{(l^2_i-l^1_i)}$ transitions made in total.


Let $L_i, \; i=1,m$ be the length of the channel $A^i$. Obviously, $l_i <= L_i, i=1,m$. The number of states in the chain is


Describe what are the states of the chain ($A_{i} B_{j} L_{k}$). How the number of states depends on the length of the channels. Why number of states is unlimited (because of $L_{k}$).

Example: zip2
  \subsection{Approximation}
Markov chains only can be used when the arrival process is memoryless (a Markov process). In our system the arrival processes are not Markov, however we can try to approximate the model with the Markov model of higher order.

Why can we assume that the arrival processes are independent? They all come from the same source.

-discrete time
-events in channels

Describe the continous case first. Show that why the discretisation is reasonable.
Describe the discrete case. How $L_{k}$ is cut (by choosing possible events $(n,a,b,ab,...)$)

How we chose the set of possible events. We want the most minimal set possible that shows the dependence of steady-state probabilities on the distribution parametes.

%TODO: Come up with a good name for it
  \subsection{How to find $T'$ and $j'$}
dT = $\frac{sum of steady-state probabilities where messages are lost)}{t_{t}}$

%or subsection?
\section{Good-enough channel length?}
$l \sim \frac{Dk}{\langle k \rangle}$, where $Dk = \sum_{k} (k - \langle k \rangle)^{2} a_{k}$, $\langle k \rangle = \sum_{k} k a_{k}$.


\section{Example: application of the Markov chain to the zip2 synchroniser}
  \subsection{Modeling the throughput}
$T = T \: (\sigma, l)$, where $\sigma = \sigma_{a} = \sigma_{b}$ - variance in both channels, $l = l_{a} = l_{b}$ - length of both channels. See \ref{fig:t_s}
    \begin{figure}[here]
    \centering
    \includegraphics[scale=0.4]{figs/thr_(disp,l).png}
    \caption{$T = T \: (\sigma, l)$.}
    \label{fig:t_s}
    \end{figure}

Explain the shape of the graph when $\mu \sim \sigma$ or $\mu >> \sigma$.
Plot a graph for $0 < \sigma < \frac{\mu}{2}$.

  \subsection{Analytical results}
-States of the chain
Why we do not consider lost messages separately for each channels in the case of zip2. 

-events in channel (the minimal set for the zip2 synchroniser)
First, we try the most minimalistic set $(n,a,b)$. Let $F_{a}(t) = Gamma(k, \theta, t)$ the distribution of interarrival times in the channels. Then the probability of one message $a$ coming to the channel $A$ in time $t_{t}$ $P_{a} = F_{a}(t_{t}) = Gamma(t_{t})$. The same is for a message $b$ coming to the channel $B$ in time $t_{t}$: $P_{b} = F_{b}(t_{t}) = Gamma(t_{t})$. Note that the discretion time $t_{t}$ must be chosen so that the ptobability os an event $ab$ in time $t_{t}$ is almost zero: $P_{ab}(t_{t}) = convolution! Gamma(t_{t})^2$. The probability to see the event $a$ arrived in $A$, channel $B$ is empty $P_{a} = Gamma(t_{t})(1-Gamma(t_{t})) = Gamma(t_{t}) - Gamma(t_{t})^2 \sim Gamma(t_{t})$. The probability to see the event $n$ (nothing arrived) in the channels over time $t_{t}$ $P_{n} = (1-p)^2 = 1 - 2 Gamma(t_{t}) + Gamma(t_{t})^2 \sim 1 - 2 Gamma(t_{t})$. The total probability of all possible events in the system $P_{n} + P_{a} + P_{b} = 1 - 2 Gamma(t_{t}) + Gamma(t_{t}) + Gamma(t_{t}) = 1$ as it should be. Then we fill the Markov transition probabilities matrix $P$ for the system's states and solve the matrix equation $xP = x$. Then we find that steady-state probabilities do not depend on the parameters of the distribution in the channels which means that we should consider more events.

Then we take the set of events $(n,a,b,ab)$, for which $P_{a} = P_{b} = Gamma(t_{t})(1 - Gamma(t_{t}))$, $P_{ab} = Gamma(t_{t})^2$ and $P_{n} = (1 - Gamma(t_{t}))^2$. For this set we see the dependence of the steady-state probabilities on $Gamma(t_{t})$.

-time $t_t$
If we expect just one message to come to a channel, then we may take the expected mean of the distribution as the discretion time $t_{t} \sim m(Gamma(k,\theta)) = k \theta$.


Build $P_{steady}$, solve $x P_{steady} = x$, dT = $\frac{\sum{x_l}}{t_t}$, $T' = T - dT$.

Expand $T'$ for $\sigma << \mu$. Plot two graphs on the same picture.
